{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jing/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jing/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/30\n",
      "950/950 [==============================] - 107s 113ms/step - loss: 0.2458 - val_loss: 0.1113\n",
      "Epoch 2/30\n",
      "950/950 [==============================] - 105s 110ms/step - loss: 0.0259 - val_loss: 0.0191\n",
      "Epoch 3/30\n",
      "950/950 [==============================] - 105s 110ms/step - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 4/30\n",
      "950/950 [==============================] - 103s 108ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 5/30\n",
      "950/950 [==============================] - 105s 110ms/step - loss: 8.4167e-04 - val_loss: 7.0661e-04\n",
      "Epoch 6/30\n",
      "950/950 [==============================] - 169s 178ms/step - loss: 6.0415e-04 - val_loss: 5.3065e-04\n",
      "Epoch 7/30\n",
      "950/950 [==============================] - 103s 108ms/step - loss: 4.8380e-04 - val_loss: 4.3022e-04\n",
      "Epoch 8/30\n",
      "950/950 [==============================] - 102s 108ms/step - loss: 4.1091e-04 - val_loss: 4.8275e-04\n",
      "Epoch 9/30\n",
      "950/950 [==============================] - 109s 115ms/step - loss: 3.6047e-04 - val_loss: 3.6315e-04\n",
      "Epoch 10/30\n",
      "950/950 [==============================] - 168s 177ms/step - loss: 3.2297e-04 - val_loss: 2.9505e-04\n",
      "Epoch 11/30\n",
      "950/950 [==============================] - 103s 109ms/step - loss: 2.9900e-04 - val_loss: 5.5683e-04\n",
      "Epoch 12/30\n",
      "950/950 [==============================] - 103s 109ms/step - loss: 2.7736e-04 - val_loss: 2.4481e-04\n",
      "Epoch 13/30\n",
      "950/950 [==============================] - 160s 168ms/step - loss: 2.5489e-04 - val_loss: 2.1957e-04\n",
      "Epoch 14/30\n",
      "950/950 [==============================] - 119s 125ms/step - loss: 2.3941e-04 - val_loss: 2.2162e-04\n",
      "Epoch 15/30\n",
      "950/950 [==============================] - 103s 108ms/step - loss: 2.2277e-04 - val_loss: 2.1767e-04\n",
      "Epoch 16/30\n",
      "950/950 [==============================] - 102s 108ms/step - loss: 2.1518e-04 - val_loss: 1.9246e-04\n",
      "Epoch 17/30\n",
      "950/950 [==============================] - 182s 192ms/step - loss: 2.0820e-04 - val_loss: 2.6725e-04\n",
      "Epoch 18/30\n",
      "950/950 [==============================] - 102s 108ms/step - loss: 1.9567e-04 - val_loss: 1.7773e-04\n",
      "Epoch 19/30\n",
      "950/950 [==============================] - 102s 107ms/step - loss: 1.8854e-04 - val_loss: 1.7392e-04\n",
      "Epoch 20/30\n",
      "950/950 [==============================] - 151s 159ms/step - loss: 1.8117e-04 - val_loss: 1.6414e-04\n",
      "Epoch 21/30\n",
      "950/950 [==============================] - 137s 144ms/step - loss: 1.7350e-04 - val_loss: 1.6357e-04\n",
      "Epoch 22/30\n",
      "950/950 [==============================] - 103s 109ms/step - loss: 1.6937e-04 - val_loss: 1.6542e-04\n",
      "Epoch 23/30\n",
      "950/950 [==============================] - 116s 122ms/step - loss: 1.6345e-04 - val_loss: 1.5844e-04\n",
      "Epoch 24/30\n",
      "950/950 [==============================] - 172s 181ms/step - loss: 1.6148e-04 - val_loss: 1.6568e-04\n",
      "Epoch 25/30\n",
      "950/950 [==============================] - 103s 109ms/step - loss: 1.5645e-04 - val_loss: 1.5565e-04\n",
      "Epoch 26/30\n",
      "950/950 [==============================] - 102s 107ms/step - loss: 1.4947e-04 - val_loss: 1.4193e-04\n",
      "Epoch 27/30\n",
      "950/950 [==============================] - 161s 169ms/step - loss: 1.4795e-04 - val_loss: 1.5458e-04\n",
      "Epoch 28/30\n",
      "950/950 [==============================] - 131s 138ms/step - loss: 1.4534e-04 - val_loss: 1.4403e-04\n",
      "Epoch 29/30\n",
      "950/950 [==============================] - 105s 110ms/step - loss: 1.3762e-04 - val_loss: 1.4322e-04\n",
      "Epoch 30/30\n",
      "950/950 [==============================] - 148s 156ms/step - loss: 1.3531e-04 - val_loss: 1.3580e-04\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#This script demonstrates the use of a convolutional LSTM network.\n",
    "This network is used to predict the next frame of an artificially\n",
    "generated movie which contains moving squares.\n",
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "# We create a layer which take as input movies of shape\n",
    "# (n_frames, width, height, channels) and returns a movie\n",
    "# of identical shape.\n",
    "\n",
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 40, 40, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "\n",
    "\n",
    "# Artificial data generation:\n",
    "# Generate movies with 3 to 7 moving squares inside.\n",
    "# The squares are of shape 1x1 or 2x2 pixels,\n",
    "# which move linearly over time.\n",
    "# For convenience we first create movies with bigger width and height (80x80)\n",
    "# and at the end we select a 40x40 window.\n",
    "\n",
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "# Train the network\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
    "        epochs=30, validation_split=0.05)\n",
    "\n",
    "# Testing the network on one movie\n",
    "# feed it with the first 7 positions and then\n",
    "# predict the new positions\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "\n",
    "\n",
    "# And then compare the predictions\n",
    "# to the ground truth\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
    "\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    plt.savefig('%i_animate.png' % (i + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
